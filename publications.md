---
layout: page
title: Publications
permalink: /publications/
---

### 2020

- **A Joint Model for Document Segmentation and Segment Labeling** (ACL 2020)<br />
  ***Joe Barrow**, Rajiv Jain, Vlad I. Morariu, Varun Manjunatha, Philip Resnik, Douglas W. Oard*

- **It Takes Two to Lie: One to Lie and One to Listen** (ACL 2020)<br />
  *Denis Peskov, Benny Cheng, Ahmed Elgohary, **Joe Barrow**, Cristian Danescu-Niculescu-Mizil, Jordan Boyd-Graber*

- **MATERIALizing Cross-Language Information Retrieval: A Snapshot**<br /> 
  (LREC 2020, CLSSTS Workshop)<br />
  *Petra Galuscakova, Douglas W. Oard, **Joe Barrow**, Suraj Nair, Han-Chin Shing, Elena Zotkina, Ramy Eskander, Rui Zhang*

### 2019

- **Mitigating Noisy Inputs for Question Answering** (INTERSPEECH 2019)<br />
  *Denis Peskov, **Joe Barrow**, Pedro Rodriguez, Graham Neubig, Jordan Boyd-Graber*

- **Unsupervised System Combination for Set-Based Retrieval with Expectation Maximization** (CLEF 2019)<br />
  *Han-Chin Shing, **Joe Barrow**, Petra Galuscakova, Douglas W. Oard, Philip Resnik*

- **Surprise Languages: Rapid-Response Cross-Language IR** (EVIA 2019)<br />
  *(Many Authors)*
  
### 2018

- **From Network to Narrative: Understanding the Nature and Trajectory of Russian Disinformation in the U.S. News** (IJPP 2018)<br />
  *Sarah Oates, **Joe Barrow**, Bobbie Foster*

### 2017

- **UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity** (SemEval 2017)<br />
  ***Joe Barrow**, Denis Peskov*

# Tutorials

 - **[AllenNLP the Hard Way](https://github.com/jbarrow/allennlp_tutorial)**<br />
   An introduction to AllenNLP, where you learn how to build a neural NER tagger from scratch.
 
 - **[An Introduction to PyTorch for NLPers](https://github.com/jbarrow/pytorch-reading-group)**<br />
   In which you can learn the basics of PyTorch. A reading group I led at UMD in 2018.

# Software

  - **[BERT from Scratch](https://github.com/jbarrow/bert_from_scratch)**<br />
    A collection of helper scripts to train a BERT model from scratch on TPUs (using Google Compute Engine).

  - **[LambdaNet](https://github.com/jbarrow/LambdaNet)**<br />
    Deep learning framework in Haskell (built in 2014, without autograd).
